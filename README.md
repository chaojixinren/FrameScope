# FrameScope——帧析云鉴系统
## 砖业团队
## 一句话口号：读懂视频，做对决策。
项目简介：
在抖音生态中，优质视频蕴含着海量信息，但用户面临理解成本高、吸收效率低、观点冲突多的痛点。FrameScope——帧析云鉴系统 通过 AI 深度读懂内容并重构表达，将碎片化的视频流转化为结构化、可验证的深度研报，让内容从“被观看”真正走向“被使用”。
1. 业务背景与痛点 (Market Context)

  项目的核心功能是围绕视频内容理解方面，
  我们观察到目前市面上的视频内容理解工具都是针对单个视频的，
  这存在一个问题：不同博主的评测观点有个人主观性与片面性，
  我们希望能同时获取多个视频，获取他们的共同描述，矛盾点，独特特征，并展示出来
2. 核心功能需求 (Functional Requirements)

功能一：跨创作者“共性与冲突”语义合成引擎 
核心逻辑：利用 AI 读懂不同视频之间的逻辑关联，将海量碎片的“观看内容”重构为结构化的“对比知识”。
- 逻辑对标与冲突探测：自动识别多个博主在同一问题上的共性、差异及隐含假设（如：博主 A 侧重性价比，博主 B 侧重纯性能）。
- 信息“脱水”与模块化重组：过滤视频中的冗余信息，按“技术原理”、“优缺点”、“适用人群”等专业维度，将非线性视频流重组为易于理解的结构化内容。
- 多维信度置信评分：基于观点出现的频次及博主专业度，对提取的结论进行加权，形成更有判定价值的理解指导。
增加一个**“共识度”指标**。例如：“关于该手机续航，全网 80% 的博主达成共识，20% 存在争议”，这种量化数据会让研报更具权威感。
- 全景视觉知识映射：自动生成横向对比矩阵或动态思维导图，让原本分散、复杂的内容变得清晰、直观。

功能二：全链路“证据闭环”决策执行中台
核心逻辑：消除 AI 幻觉，将理解后的内容转化为用户可验证、可直接使用的工具能力。
-  原子级证据链回溯：报告中的每一个对比结论均附带时间戳锚点，系统自动提取并生成关键帧截图，点击即可瞬间跳转至原视频的精准秒数，实现内容"真实可证"，让 AI 生成的每一句话都有据可查。
-  可交互决策导向输出：生成的不仅是文字，更是结构化的 Markdown 知识库，关键结论与时间戳标记深度融合，形成可追溯、可验证的证据链，让视频内容真正沉淀为可复用的生产力资产。
-  从"观看"到"行动"的智能闭环：通过智能对话引擎，首次提问自动完成视频搜索和深度总结，后续提问基于历史上下文进行精准追问，保留完整对话记忆，让用户从"被动观看"转向"主动决策"，完成内容应用的完整闭环。
3. 技术栈及相关实现
3.1 技术栈组成
- 前端vue3+ts
- 后端python fastapi langgraph
- 数据库sqlite
- 文本模型qwen、STT使用whisper或groq
3.2 graph的结构组成
1. video_search_node（视频搜索节点）
  - 扩展搜索关键词，调用 Bilibili API 搜索并筛选前 5 个高质量视频
  - Return: 多个视频 URL
2. note_generation_node（笔记生成节点）
  - 异步并发生成所有视频的笔记（视频下载 → 语音转文字 → LLM 生成观点解析）
  - Return: 多个观点解析（包含 markdown、transcript、时间戳等）
3. summary_node（总结节点）
  - 使用 ReAct Agent 进行多视频总结，识别共同观点、冲突点、独特特征
  - 生成结构化 Markdown 总结，关键结论附带时间戳标记
  - Return: 最终总结（Markdown 格式）
4. trace_node（证据链回溯节点）
  - 提取时间戳标记，生成关键帧截图并插入到 Markdown 中
  - Return: {时间戳键: {video_url, frame_url, video_id, timestamp, platform}}
后续提问流程（chat → END）： 
5.  chat_node（普通对话节点）
- 基于之前的总结内容进行深入讨论，保留完整对话历史
- Return: 对话回复